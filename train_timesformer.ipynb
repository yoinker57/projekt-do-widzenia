{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TimeSformer Exercise Prediction\n",
                "\n",
                "This notebook trains a TimeSformer model to predict exercises from video data.\n",
                "Data is located in `data/`, with videos in `data/films/` and labels in CSV files.\n",
                "We use `split.csv` to divide data into training and testing sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import TimesformerForVideoClassification, VideoMAEImageProcessor, TrainingArguments, Trainer\n",
                "from transformers import AutoImageProcessor, AutoModelForVideoClassification\n",
                "import decord\n",
                "from decord import VideoReader, cpu\n",
                "from PIL import Image\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Ensure decord works correctly\n",
                "decord.bridge.set_bridge('torch')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = 'data'\n",
                "FILMS_DIR = os.path.join(DATA_DIR, 'films')\n",
                "SPLIT_FILE = 'split.csv'\n",
                "MODEL_CKPT = \"facebook/timesformer-base-finetuned-k400\"\n",
                "BATCH_SIZE = 4\n",
                "NUM_FRAMES = 8 # Number of frames to sample per clip\n",
                "RESIZE_TO = 224"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Preprocessing\n",
                "\n",
                "We need to parse the CSV files to identify labeled segments (clips). \n",
                "Each row in a CSV corresponds to a frame. We look for continuous segments of valid labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing 60 files...\n",
                        "Missing file for ID: 027_e84uoke1\n",
                        "Train clips: 3165, Test clips: 3179\n",
                        "Unique labels: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
                    ]
                }
            ],
            "source": [
                "def parse_intervals(csv_path):\n",
                "    \"\"\"\n",
                "    Parses a CSV file to find labeled intervals.\n",
                "    Returns a list of dicts: {'label': label, 'start_frame': start, 'end_frame': end}\n",
                "    \"\"\"\n",
                "    # Reading CSV without header, assume 3 columns: frame_info, unused, label_id\n",
                "    try:\n",
                "        df = pd.read_csv(csv_path, header=None)\n",
                "    except pd.errors.EmptyDataError:\n",
                "        return []\n",
                "        \n",
                "    # Assuming column 0 is frame, column 2 is label\n",
                "    # Labels like -001 are background/ignore\n",
                "    \n",
                "    intervals = []\n",
                "    if len(df) == 0:\n",
                "        return intervals\n",
                "\n",
                "    current_label = None\n",
                "    start_frame = None\n",
                "    \n",
                "    labels = df.iloc[:, 2].values\n",
                "\n",
                "    for i, label in enumerate(labels):\n",
                "        if label != -1: # Valid label\n",
                "            if current_label is None:\n",
                "                current_label = label\n",
                "                start_frame = i \n",
                "            elif label != current_label:\n",
                "                # Label changed, save previous interval\n",
                "                intervals.append({\n",
                "                    'label': current_label,\n",
                "                    'start_frame': start_frame,\n",
                "                    'end_frame': i - 1\n",
                "                })\n",
                "                current_label = label\n",
                "                start_frame = i\n",
                "        else:\n",
                "            if current_label is not None:\n",
                "                # Interval ended\n",
                "                intervals.append({\n",
                "                    'label': current_label,\n",
                "                    'start_frame': start_frame,\n",
                "                    'end_frame': i - 1\n",
                "                })\n",
                "                current_label = None\n",
                "                start_frame = None\n",
                "    \n",
                "    # Add last interval if exists\n",
                "    if current_label is not None:\n",
                "        intervals.append({\n",
                "            'label': current_label,\n",
                "            'start_frame': start_frame,\n",
                "            'end_frame': len(labels) - 1\n",
                "        })\n",
                "        \n",
                "    return intervals\n",
                "\n",
                "def prepare_dataset(split_file): \n",
                "    split_df = pd.read_csv(split_file)\n",
                "    \n",
                "    train_clips = []\n",
                "    test_clips = []\n",
                "    \n",
                "    all_labels = set()\n",
                "\n",
                "    print(f\"Processing {len(split_df)} files...\")\n",
                "    \n",
                "    for _, row in split_df.iterrows():\n",
                "        file_id = row['id']\n",
                "        split_type = row['split']\n",
                "        \n",
                "        csv_path = os.path.join(DATA_DIR, f\"{file_id}.csv\")\n",
                "        video_path = os.path.join(FILMS_DIR, f\"{file_id}.mp4\")\n",
                "        \n",
                "        if not os.path.exists(csv_path) or not os.path.exists(video_path):\n",
                "            print(f\"Missing file for ID: {file_id}\")\n",
                "            continue\n",
                "            \n",
                "        intervals = parse_intervals(csv_path)\n",
                "        \n",
                "        for interval in intervals:\n",
                "            clip = {\n",
                "                'video_path': video_path,\n",
                "                'start_frame': interval['start_frame'],\n",
                "                'end_frame': interval['end_frame'],\n",
                "                'label': interval['label']\n",
                "            }\n",
                "            \n",
                "            all_labels.add(interval['label'])\n",
                "            \n",
                "            if split_type == 'train':\n",
                "                train_clips.append(clip)\n",
                "            else:\n",
                "                test_clips.append(clip)\n",
                "                \n",
                "    return train_clips, test_clips, sorted(list(all_labels))\n",
                "\n",
                "train_clips, test_clips, unique_labels = prepare_dataset(SPLIT_FILE)\n",
                "print(f\"Train clips: {len(train_clips)}, Test clips: {len(test_clips)}\")\n",
                "print(f\"Unique labels: {unique_labels}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Label Mappings: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15}\n"
                    ]
                }
            ],
            "source": [
                "# Create label mappings\n",
                "# Convert numpy types to native python types for JSON serialization\n",
                "label2id = {int(label): int(i) for i, label in enumerate(unique_labels)}\n",
                "id2label = {int(i): int(label) for label, i in label2id.items()}\n",
                "print(\"Label Mappings:\", label2id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ExerciseDataset(Dataset):\n",
                "    def __init__(self, clips, processor, num_frames=8):\n",
                "        self.clips = clips\n",
                "        self.processor = processor\n",
                "        self.num_frames = num_frames\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.clips)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        clip = self.clips[idx]\n",
                "        video_path = clip['video_path']\n",
                "        start_f = clip['start_frame']\n",
                "        end_f = clip['end_frame']\n",
                "        label = clip['label']\n",
                "\n",
                "        # Load video\n",
                "        try:\n",
                "            vr = VideoReader(video_path, ctx=cpu(0))\n",
                "        except Exception as e:\n",
                "            print(f\"Error reading {video_path}: {e}\")\n",
                "            return self.__getitem__((idx + 1) % len(self))\n",
                "\n",
                "        total_frames = len(vr)\n",
                "        \n",
                "        start_f = max(0, min(start_f, total_frames - 1))\n",
                "        end_f = max(0, min(end_f, total_frames - 1))\n",
                "        \n",
                "        if start_f >= end_f:\n",
                "             indices = [start_f] * self.num_frames\n",
                "        else:\n",
                "            # Sample indices evenly\n",
                "            indices = np.linspace(start_f, end_f, self.num_frames).astype(int)\n",
                "\n",
                "        video = vr.get_batch(indices)\n",
                "        if hasattr(video, 'asnumpy'):\n",
                "            video = video.asnumpy()\n",
                "        else:\n",
                "            video = video.numpy()\n",
                "        \n",
                "        # Normalize and process\n",
                "        inputs = self.processor(list(video), return_tensors=\"pt\")\n",
                "        \n",
                "        return {\n",
                "            \"pixel_values\": inputs.pixel_values.squeeze(), # (num_frames, 3, 224, 224)\n",
                "            \"labels\": torch.tensor(label2id[label])\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n",
                        "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([16, 768]) in the model instantiated\n",
                        "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([16]) in the model instantiated\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                }
            ],
            "source": [
                "# Processor and Model\n",
                "processor = AutoImageProcessor.from_pretrained(MODEL_CKPT)\n",
                "model = TimesformerForVideoClassification.from_pretrained(\n",
                "    MODEL_CKPT,\n",
                "    num_labels=len(unique_labels),\n",
                "    id2label=id2label,\n",
                "    label2id=label2id,\n",
                "    ignore_mismatched_sizes=True \n",
                ")\n",
                "\n",
                "train_dataset = ExerciseDataset(train_clips, processor, num_frames=NUM_FRAMES)\n",
                "test_dataset = ExerciseDataset(test_clips, processor, num_frames=NUM_FRAMES)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "args = TrainingArguments(\n",
                "    output_dir=\"timesformer_results\",\n",
                "    remove_unused_columns=False,\n",
                "    eval_strategy=\"epoch\",\n",
                "    save_strategy=\"epoch\",\n",
                "    learning_rate=5e-5,\n",
                "    per_device_train_batch_size=BATCH_SIZE,\n",
                "    per_device_eval_batch_size=BATCH_SIZE,\n",
                "    gradient_accumulation_steps=4, \n",
                "    warmup_ratio=0.1,\n",
                "    logging_steps=10,\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=\"accuracy\",\n",
                "    num_train_epochs=3,\n",
                "    fp16=True if torch.cuda.is_available() else False,\n",
                "    \n",
                "    report_to=\"none\",\n",
                "    logging_dir=\"./logs\",\n",
                "    disable_tqdm=False,\n",
                ")\n",
                "\n",
                "def compute_metrics(eval_pred):\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=test_dataset,\n",
                "    compute_metrics=compute_metrics,\n",
                "    \n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting training...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='594' max='594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [594/594 33:12, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.035100</td>\n",
                            "      <td>0.230442</td>\n",
                            "      <td>0.944322</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>0.016400</td>\n",
                            "      <td>0.183605</td>\n",
                            "      <td>0.958792</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>0.001100</td>\n",
                            "      <td>0.177067</td>\n",
                            "      <td>0.960994</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "TrainOutput(global_step=594, training_loss=0.20587469969785174, metrics={'train_runtime': 1995.768, 'train_samples_per_second': 4.758, 'train_steps_per_second': 0.298, 'total_flos': 8.319757294526792e+18, 'train_loss': 0.20587469969785174, 'epoch': 3.0})"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print(\"Starting training...\")\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer.save_model(\"./models/model1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model wczytany pomyślnie!\n"
                    ]
                }
            ],
            "source": [
                "test_model = AutoModelForVideoClassification.from_pretrained(\"./models/model1\")\n",
                "print(\"Model wczytany pomyślnie!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
